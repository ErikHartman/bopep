{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ErikHartman/bopep/blob/main/bopep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2L-Q7cEeUXx"
      },
      "source": [
        "# bopep: identifying peptide binders in large scale peptidomic data\n",
        "\n",
        "Bayesian optimization guided search for binders in large scale peptidomic datasets.\n",
        "\n",
        "Relies on ESM2 for peptide embeddings, ColabFold utilizing AlphaFold 2 multimer for docking and PyRosetta for interface energy calculations. A deep ensemble is used as a surrogate model utilizing Torch.\n",
        "\n",
        "Set runtime to GPU (T4)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wX-T-BaXe8NS",
        "outputId": "1eb73fb3-d37a-4031-97e5-232cd3b844f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching bopep\n",
            "Cloning into '/content/bopep'...\n",
            "remote: Enumerating objects: 38, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 38 (delta 12), reused 22 (delta 4), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (38/38), 26.44 KiB | 13.22 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n",
            "Installing ColabFold\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m360.3/360.3 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.0/230.0 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\n",
            "mizani 0.13.0 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "opentelemetry-api 1.28.0 requires importlib-metadata<=8.5.0,>=6.0, but you have importlib-metadata 4.13.0 which is incompatible.\n",
            "plotnine 0.14.1 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "tensorflow 2.17.0 requires tensorboard<2.18,>=2.17, but you have tensorboard 2.18.0 which is incompatible.\n",
            "xarray 2024.10.0 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mInstalling esm-fair and fetching ESM model\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ESM model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t33_650M_UR50D.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D.pt\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t33_650M_UR50D-contact-regression.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D-contact-regression.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing PyRosetta\n",
            "Collecting pyrosettacolabsetup\n",
            "  Downloading pyrosettacolabsetup-1.0.9-py3-none-any.whl.metadata (294 bytes)\n",
            "Downloading pyrosettacolabsetup-1.0.9-py3-none-any.whl (4.9 kB)\n",
            "Installing collected packages: pyrosettacolabsetup\n",
            "Successfully installed pyrosettacolabsetup-1.0.9\n",
            "\n",
            "Note that USE OF PyRosetta FOR COMMERCIAL PURPOSES REQUIRE PURCHASE OF A LICENSE.\n",
            "See https://github.com/RosettaCommons/rosetta/blob/main/LICENSE.md or email license@uw.edu for details.\n",
            "\n",
            "Looking for compatible PyRosetta wheel file at google-drive/PyRosetta/colab.bin//wheels.serialization...\n",
            "Downloading PyRosetta package...\n",
            "\n",
            "Resolving west.rosettacommons.org (west.rosettacommons.org)... 128.95.160.153, 2607:4000:406::160:153\n",
            "\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://west.rosettacommons.org/pyrosetta/release/release/PyRosetta4.Release.python310.ubuntu.cxx11thread.serialization.wheel/pyrosetta-2024.42+release.3366cf78a3-cp310-cp310-linux_x86_64.whl [following]\n",
            "--2024-11-13 04:21:36--  https://west.rosettacommons.org/pyrosetta/release/release/PyRosetta4.Release.python310.ubuntu.cxx11thread.serialization.wheel/pyrosetta-2024.42+release.3366cf78a3-cp310-cp310-linux_x86_64.whl\n",
            "\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1576918002 (1.5G)\n",
            "--2024-11-13 04:21:37--  https://west.rosettacommons.org/pyrosetta/release/release/PyRosetta4.Release.python310.ubuntu.cxx11thread.serialization.wheel/pyrosetta-2024.42+release.3366cf78a3-cp310-cp310-linux_x86_64.whl\n",
            "Reusing existing connection to west.rosettacommons.org:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1576918002 (1.5G)\n",
            "Saving to: ‘/PyRosetta/colab.bin/tmps9szfnea/pyrosetta-2024.42+release.3366cf78a3-cp310-cp310-linux_x86_64.whl’\n",
            "\n",
            "pyrosetta-2024.42+r 100%[===================>]   1.47G  9.93MB/s    in 2m 30s  \n",
            "\n",
            "2024-11-13 04:24:08 (10.0 MB/s) - ‘/PyRosetta/colab.bin/tmps9szfnea/pyrosetta-2024.42+release.3366cf78a3-cp310-cp310-linux_x86_64.whl’ saved [1576918002/1576918002]\n",
            "Moving wheel file pyrosetta-2024.42+release.3366cf78a3-cp310-cp310-linux_x86_64.whl to target dir /PyRosetta/colab.bin/wheels.serialization...\n",
            "Installing PyRosetta wheel '/PyRosetta/colab.bin/wheels.serialization/pyrosetta-2024.42+release.3366cf78a3-cp310-cp310-linux_x86_64.whl'...\n",
            "\n",
            "\n",
            "Installing other necessary packages\n"
          ]
        }
      ],
      "source": [
        "#@title Installation\n",
        "\n",
        "import os\n",
        "\n",
        "print(\"Fetching bopep\")\n",
        "!git clone https://github.com/ErikHartman/bopep /content/bopep/\n",
        "\n",
        "print(\"Installing ColabFold\")\n",
        "!pip install --quiet colabfold\n",
        "!pip install --quiet biopython\n",
        "\n",
        "print(\"Installing esm-fair and fetching ESM model\")\n",
        "!pip install --quiet fair-esm\n",
        "\n",
        "# Code to fetch ESM model if it doesn't already exist\n",
        "esm_model_path = \"/root/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D.pt\"\n",
        "if not os.path.exists(esm_model_path):\n",
        "    print(\"Downloading ESM model...\")\n",
        "    import esm\n",
        "    model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
        "else:\n",
        "    print(\"ESM model already exists.\")\n",
        "\n",
        "print(\"Installing PyRosetta\")\n",
        "!pip install pyrosettacolabsetup\n",
        "import pyrosettacolabsetup\n",
        "pyrosettacolabsetup.install_pyrosetta(serialization=True, cache_wheel_on_google_drive=False)\n",
        "\n",
        "print(\"Installing other necessary packages\")\n",
        "!pip install -r https://raw.githubusercontent.com/ErikHartman/bopep/main/requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-sd12-jfCBl",
        "outputId": "628b49b1-f6a1-4d9f-8036-2dc2e68248ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/bopep\n",
            "Data file: data/test_data.csv\n",
            "Max length: 30\n",
            "Min length: 5\n",
            "Max repeat length: 5\n",
            "Max single amino acid fraction: 0.73\n"
          ]
        }
      ],
      "source": [
        "#@title Embedding settings\n",
        "import pandas as pd\n",
        "\n",
        "%cd bopep\n",
        "\n",
        "# Data input\n",
        "# @markdown Upload your input data file and set the path to the path relative to /bopep.\n",
        "data_file = \"data/test_data.csv\" #@param {type:\"string\"}\n",
        "\n",
        "if not os.path.exists(data_file):\n",
        "  raise ValueError(\"The data file does not exist in the path.\")\n",
        "\n",
        "data = pd.read_csv(data_file)  # Load the CSV file\n",
        "peptides = data[\"peptide\"].tolist()\n",
        "# @markdown  ### Filtering options:\n",
        "\n",
        "# @markdown Set maximum and minimum peptide length\n",
        "max_length = 30  #@param {type:\"slider\", min:10, max:60, step:1}\n",
        "min_length = 5   #@param {type:\"slider\", min:1, max:30, step:1}\n",
        "\n",
        "# @markdown Set maximum repeat length for amino acids\n",
        "max_repeat_length = 5  #@param {type:\"slider\", min:1, max:15, step:1}\n",
        "\n",
        "# @markdown  Set maximum allowed fraction of single amino acids\n",
        "max_single_aa_fraction = 0.73  #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "# @markdown  Variance kept during PCA reduction\n",
        "pca_variance = 0.95  #@param {type:\"slider\", min:0.1, max:1, step:0.01}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duvhwIxSh338",
        "outputId": "bef5288d-a599-404a-992f-54ed36c52e45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/esm/pretrained.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_data = torch.load(str(model_location), map_location=\"cpu\")\n",
            "/usr/local/lib/python3.10/dist-packages/esm/pretrained.py:74: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  regression_data = torch.load(regression_location, map_location=\"cpu\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model from local path: /root/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating embeddings: 100%|██████████| 16/16 [06:22<00:00, 23.89s/it]\n"
          ]
        }
      ],
      "source": [
        "#@title Generate embeddings\n",
        "from src.embeddings.embed import embed\n",
        "from src.embeddings.utils import filter_peptides\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "\n",
        "filtered_peptides = filter_peptides(peptides, max_single_aa_fraction, max_repeat_length, min_length, max_length)\n",
        "emeddings = embed(filtered_peptides, model_path=esm_model_path)\n",
        "\n",
        "if pca_variance < 1:\n",
        "  embedding_array = np.array(list(emeddings.values()))\n",
        "  peptide_sequences = list(emeddings.keys())\n",
        "  pca = PCA(n_components=0.95, svd_solver=\"full\")\n",
        "  embeddings_reduced = pca.fit_transform(embedding_array)\n",
        "  print(f\"Reduced embedding size: {np.shape(embeddings_reduced)} (before PCA: {np.shape(embedding_array)})\")\n",
        "  embeddings = {\n",
        "      peptide_sequences[i]: embeddings_reduced[i] for i in range(len(peptide_sequences))\n",
        "  }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zz07Koj-fIWi"
      },
      "outputs": [],
      "source": [
        "#@title Bayesian optimization settings\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QKSu6-tsfP9l"
      },
      "outputs": [],
      "source": [
        "#@title Initialize PyRosetta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4MDxL37ufKuH"
      },
      "outputs": [],
      "source": [
        "#@title Run bopep!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}